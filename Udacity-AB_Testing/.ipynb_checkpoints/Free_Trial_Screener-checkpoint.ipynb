{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free Trail Screener Project\n",
    "\n",
    "At the time of this experiment, Udacity courses currently have two options on the course overview page: **start free trial**, and **access course materials**. \n",
    "\n",
    "If the student clicks \"start free trial\", they will be asked to enter their credit card information, and then they will be enrolled in a free trial for the paid version of the course. After 14 days, they will automatically be charged unless they cancel first. \n",
    "\n",
    "If the student clicks \"access course materials\", they will be able to view the videos and take the quizzes for free, but they will not receive coaching support or a verified certificate, and they will not submit their final project for feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the experiment, Udacity tested a change where if the student clicked \"start free trial\", they were asked how much time they had available to devote to the course. If the student indicated 5 or more hours per week, they would be taken through the checkout process as usual. If they indicated fewer than 5 hours per week, a message would appear indicating that Udacity courses usually require a greater time commitment for successful completion, and suggesting that the student might like to access the course materials for free. At this point, the student would have the option to continue enrolling in the free trial, or access the course materials for free instead. \n",
    "\n",
    "The hypothesis was that this might set clearer expectations for students upfront, thus reducing the number of frustrated students who left the free trial because they didn't have enough timeâ€”without significantly reducing the number of students to continue past the free trial and eventually complete the course. If this hypothesis held true, Udacity could improve the overall student experience and improve coaches' capacity to support students who are likely to complete the course.\n",
    "\n",
    "\n",
    "The **unit of diversion** is a **cookie**, although if the student enrolls in the free trial, they are tracked by user-id from that point forward. The same user-id cannot enroll in the free trial twice. For users that do not enroll, their user-id is not tracked in the experiment, even if they were signed in when they visited the course overview page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Choice\n",
    "List which metrics you will use as invariant metrics and evaluation metrics here.\n",
    "\n",
    "For each metric, explain both why you did or did not use it as an invariant metric and why you did or did not use it as an evaluation metric. Also, state what results you will look for in your evaluation metrics in order to launch the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Invariant Metrics**\n",
    "1. Number of cookies\n",
    "\n",
    "Number of unique cookies to see the course overview page. The unit of diversion and distribution amongst the control and experiment groups are expected to be the same because the setup of controlled and experimented groups assigns two similarily same number of cookies.\n",
    "\n",
    "2. Number of clicks\n",
    "\n",
    "Number of unique cookies to click the \"Start free trial\" button. Since users got asked how much time to complete a course before seeing the page, the unit of diversion between control and experiment groups are expected to be the same. \n",
    "\n",
    "3. Click-through-probability\n",
    "\n",
    "Number of unique cookies to click the \"Start free trial\" button divided by number of unique cookies to view the course overview page. It is expected to be the same because users see the change before clicking.\n",
    "\n",
    "**Evaluation Metrics**\n",
    "1. Gross conversion\n",
    "\n",
    "Number of user-ids to complete checkout and enroll in the free trial divided by number of unique cookies to click the \"Start free trial\" button.\n",
    "\n",
    "2. Retention\n",
    "\n",
    "Number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by number of user-ids to complete checkout.\n",
    "\n",
    "3. Net conversion\n",
    "\n",
    "Number of users who enroll in the free trial. After 14 days, users will determine to use it or not, so we could utilize it as our evaluation metric.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Standard Deviation\n",
    "List the standard deviation of each of your evaluation metrics given a sample size of 5000 cookies.\n",
    "\n",
    "For each of your evaluation metrics, indicate whether you think the analytic estimate would be comparable to the the empirical variability, or whether you expect them to be different (in which case it might be worth doing an empirical estimate if there is time). Briefly give your reasoning in each case. \n",
    "\n",
    "| Metrics | Baseline value  |\n",
    "|:--------|:-------|\n",
    "|Unique cookies to view course overview page per day |40000|\n",
    "|Unique cookies to click \"Start free trial\" per day| 3200|\n",
    "|Enrollments per day|660|\n",
    "|Click-through-probability on \"Start free trial\"|0.08|\n",
    "|Probability of enrolling, given click|0.20625|\n",
    "|Probability of payment, given enroll|0.53|\n",
    "|Probability of payment, given click|0.1093125|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SE(prob, size):\n",
    "    return ((prob * (1-prob))/size)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE of gross conversion 0.020230604137049392\n",
      "SE of retention 0.05494901217850908\n",
      "SE of net conversion 0.01560154458248846\n"
     ]
    }
   ],
   "source": [
    "# gross conversion\n",
    "prob_enroll = 0.20625\n",
    "size_gross_conversion = 5000 * 0.08\n",
    "# retention\n",
    "prob_payment_enroll = 0.53\n",
    "size_retention = 5000 * 0.08 * 0.20625\n",
    "# net conversion\n",
    "prob_conversion = 0.1093125\n",
    "size_net_conversion = 5000 * 0.08\n",
    "\n",
    "print(\"SE of gross conversion\", SE(prob_enroll, size_gross_conversion))\n",
    "print(\"SE of retention\", SE(prob_payment_enroll, size_retention))\n",
    "print(\"SE of net conversion\", SE(prob_conversion, size_net_conversion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sizing\n",
    "\n",
    "Indicate whether you will use the Bonferroni correction during your analysis phase, and give the number of pageviews you will need to power you experiment appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonferroni Correction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3939797998185104"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "alpha_overall = 0.05\n",
    "alpha_bonferroni = alpha_overall / 3\n",
    "st.norm.ppf(1-alpha_bonferroni/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gross conversion: That is, number of user-ids to complete checkout and enroll in the free trial divided by number of unique cookies to click the \"Start free trial\" button. (dmin= 0.01)\n",
    "\n",
    "* Retention: That is, number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by number of user-ids to complete checkout. (dmin=0.01)\n",
    "\n",
    "* Net conversion: That is, number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by the number of unique cookies to click the \"Start free trial\" button. (dmin= 0.0075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Margin Error of gross conversion 0.04843165764222103\n",
      "Margin Error of retention 0.13154682517533206\n",
      "Margin Error of net conversion 0.03734978257644529\n"
     ]
    }
   ],
   "source": [
    "print(\"Margin Error of gross conversion\", 2.3939797998185104 * SE(prob_enroll, size_gross_conversion))\n",
    "print(\"Margin Error of retention\", 2.3939797998185104 * SE(prob_payment_enroll, size_retention))\n",
    "print(\"Margin Error of net conversion\", 2.3939797998185104 * SE(prob_conversion, size_net_conversion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By caculating confidence intervals of dmin, we could see some metric contain 0. So it is not significant. We won't use Bonferroni Correction right now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choosing Number of Samples given Power**\n",
    "\n",
    "Using the analytic estimates of variance, how many pageviews total (across both groups) would you need to collect to adequately power the experiment? Use an alpha of 0.05 and a beta of 0.2. Make sure you have enough power for each metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use online sample size calculator.\n",
    "(https://www.evanmiller.org/ab-testing/sample-size.html)\n",
    "\n",
    "Gross Conversion:\\\n",
    "Baseline Conversion Rate: 0.20625 / Minimum Detectable Effect: 0.01 -> Sample Size: 25835\\\n",
    "Total Sample Size (Control&Experiment): 25835 * 2 = 51670 (clicks)\\\n",
    "Pageviews: 51670/0.08 = 645875\n",
    "\n",
    "Retention:\\\n",
    "Baseline Conversion Rate: 0.53 / Minimum Detectable Effect: 0.01 -> Sample Size: 39115\\\n",
    "Total Sample Size (Control&Experiment): 39115 * 2 = 78230 (enrolls)\\\n",
    "Pageviews: 78230/(660/40000) = 4741212\n",
    "\n",
    "Net Conversion:\n",
    "Baseline Conversion Rate: 0.1093125 / Minimum Detectable Effect: 0.0075 -> Sample Size: 27413 \\\n",
    "Total Sample Size (Control&Experiment): 27413 * 2 = 54826 (clicks)\\\n",
    "Pageviews: 54826/0.08 = 685325"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We will design functions to get the sample size. (Source:https://stats.stackexchange.com/questions/392979/ab-test-sample-size-calculation-by-hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities to get sample size\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "def get_sample_size(alpha, beta, baseline, detectable_effect):\n",
    "    get_alpha_ppf = norm.ppf(alpha/2)\n",
    "    get_beta_ppf = norm.ppf(beta)\n",
    "    p1 = baseline\n",
    "    p2 = p1 + detectable_effect\n",
    "    left_part = get_alpha_ppf * np.sqrt(2 * p1 * (1-p1))\n",
    "    right_part = get_beta_ppf * np.sqrt(p1 * (1-p1)+ p2 * (1-p2))\n",
    "    nominator = (left_part + right_part) ** 2\n",
    "    denominator = (p2 - p1) ** 2\n",
    "    return nominator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25834.700007480867"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gross conversion\n",
    "get_sample_size(0.05, 0.2, 0.20625, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39086.60966243208"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retention\n",
    "get_sample_size(0.05, 0.2, 0.53, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27413.33789636357"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Net Conversion\n",
    "get_sample_size(0.05, 0.2, 0.1093125 , 0.0075)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration vs. Exposure\n",
    "\n",
    "What percentage of Udacity's traffic would you divert to this experiment (assuming there were no other experiments you wanted to run simultaneously)? Is the change risky enough that you wouldn't want to run on all traffic?\n",
    "\n",
    "Given the percentage you chose, how long would the experiment take to run, using the analytic estimates of variance? If the answer is longer than a few weeks, then this is unreasonably long, and you should reconsider an earlier decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 100\\% percentage of traffic to run this experiment.\n",
    "\n",
    "| Pageviews | Days  |\n",
    "|:--------|:-------|\n",
    "|Gross Conversion |16.14|\n",
    "|Retention| 118.5|\n",
    "|Net Conversion|17.13|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates=['Sat, Oct 11', 'Sun, Oct 12', 'Mon, Oct 13', 'Tue, Oct 14',\n",
    "       'Wed, Oct 15', 'Thu, Oct 16', 'Fri, Oct 17', 'Sat, Oct 18',\n",
    "       'Sun, Oct 19', 'Mon, Oct 20', 'Tue, Oct 21', 'Wed, Oct 22',\n",
    "       'Thu, Oct 23', 'Fri, Oct 24', 'Sat, Oct 25', 'Sun, Oct 26',\n",
    "       'Mon, Oct 27', 'Tue, Oct 28', 'Wed, Oct 29', 'Thu, Oct 30',\n",
    "       'Fri, Oct 31', 'Sat, Nov 1', 'Sun, Nov 2', 'Mon, Nov 3',\n",
    "       'Tue, Nov 4', 'Wed, Nov 5', 'Thu, Nov 6', 'Fri, Nov 7',\n",
    "       'Sat, Nov 8', 'Sun, Nov 9', 'Mon, Nov 10', 'Tue, Nov 11',\n",
    "       'Wed, Nov 12', 'Thu, Nov 13', 'Fri, Nov 14', 'Sat, Nov 15',\n",
    "       'Sun, Nov 16']\n",
    "pageviews_cont=[ 7723,  9102, 10511,  9871, 10014,  9670,  9008,  7434,  8459,\n",
    "       10667, 10660,  9947,  8324,  9434,  8687,  8896,  9535,  9363,\n",
    "        9327,  9345,  8890,  8460,  8836,  9437,  9420,  9570,  9921,\n",
    "        9424,  9010,  9656, 10419,  9880, 10134,  9717,  9192,  8630,\n",
    "        8970]\n",
    "pageviews_exp=[ 7716,  9288, 10480,  9867,  9793,  9500,  9088,  7664,  8434,\n",
    "       10496, 10551,  9737,  8176,  9402,  8669,  8881,  9655,  9396,\n",
    "        9262,  9308,  8715,  8448,  8836,  9359,  9427,  9633,  9842,\n",
    "        9272,  8969,  9697, 10445,  9931, 10042,  9721,  9304,  8668,\n",
    "        8988]\n",
    "clicks_cont=[687, 779, 909, 836, 837, 823, 748, 632, 691, 861, 867, 838, 665,\n",
    "       673, 691, 708, 759, 736, 739, 734, 706, 681, 693, 788, 781, 805,\n",
    "       830, 781, 756, 825, 874, 830, 801, 814, 735, 743, 722]\n",
    "clicks_exp=[686, 785, 884, 827, 832, 788, 780, 652, 697, 860, 864, 801, 642,\n",
    "       697, 669, 693, 771, 736, 727, 728, 722, 695, 724, 789, 743, 808,\n",
    "       831, 767, 760, 850, 851, 831, 802, 829, 770, 724, 710]\n",
    "enrolls_cont=[134, 147, 167, 156, 163, 138, 146, 110, 131, 165, 196, 162, 127,\n",
    "       220, 176, 161, 233, 154, 196, 167, 174, 156, 206]\n",
    "enrolls_exp=[105, 116, 145, 138, 140, 129, 127,  94, 120, 153, 143, 128, 122,\n",
    "       194, 127, 153, 213, 162, 201, 207, 182, 142, 182]\n",
    "payment_cont=[ 70,  70,  95, 105,  64,  82,  76,  70,  60,  97, 105,  92,  56,\n",
    "       122, 128, 104, 124,  91,  86,  75, 101,  93,  67]\n",
    "payment_exp=[ 34,  91,  79,  92,  94,  61,  44,  62,  77,  98,  71,  70,  68,\n",
    "        94,  81, 101, 119, 120,  96,  67, 123, 100, 103]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Checks\n",
    "For each of your invariant metrics, give the 95% confidence interval for the value you expect to observe, the actual observed value, and whether the metric passes your sanity check. \n",
    "\n",
    "For any sanity check that did not pass, explain your best guess as to what went wrong based on the day-by-day data. Do not proceed to the rest of the analysis unless all sanity checks pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_confidence_interval(num_control, num_experiment):\n",
    "    sum_cont=sum(num_control)\n",
    "    sum_exp=sum(num_experiment)\n",
    "    SD=math.sqrt(0.5*0.5/(sum_cont+sum_exp))\n",
    "    m=1.96*SD\n",
    "    ci_min,ci_max=0.5-m,0.5+m\n",
    "    print(\"Confidence Interval: [{},{}]\".format(round(ci_min,4),round(ci_max,4)))\n",
    "    print(\"Observed: \",round(sum_cont/(sum_exp+sum_cont),4))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval: [0.4988,0.5012]\n",
      "Observed:  0.5006\n"
     ]
    }
   ],
   "source": [
    "# Pageviews\n",
    "get_confidence_interval(pageviews_cont, pageviews_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval: [0.4959,0.5041]\n",
      "Observed:  0.5005\n"
     ]
    }
   ],
   "source": [
    "# number of clicks\n",
    "get_confidence_interval(clicks_cont, clicks_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval for ctp: [-0.0013,0.0013]\n",
      "Observed:  0.0001\n"
     ]
    }
   ],
   "source": [
    "# click_through_probability\n",
    "ctp_cont = sum(clicks_cont)/sum(pageviews_cont)\n",
    "ctp_exp = sum(clicks_exp)/sum(pageviews_exp)\n",
    "d_hat = ctp_exp-ctp_cont\n",
    "ctp_pool = (sum(clicks_cont)+sum(clicks_exp))/(sum(pageviews_cont)+sum(pageviews_exp))\n",
    "SE_ctp = math.sqrt(ctp_pool*(1-ctp_pool)*(1/sum(pageviews_cont)+1/sum(pageviews_exp)))\n",
    "m = 1.96 * SE_ctp\n",
    "ci_min, ci_max = -m, m\n",
    "print(\"Confidence Interval for ctp: [{},{}]\".format(round(ci_min,4),round(ci_max,4)))\n",
    "print(\"Observed: \",round(d_hat,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Analysis\n",
    "\n",
    "Source:https://nancyyanyu.github.io/posts/8fdfc10f/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effect Size Tests\n",
    "For each of your evaluation metrics, give a 95% confidence interval around the difference between the experiment and control groups. Indicate whether each metric is statistically and practically significant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval:[-0.0291233583354044,-0.01198639082531873]\n",
      "Observed: -0.020554874580361565\n",
      "Statistically significant: True ,  CI doesn't include 0\n",
      "Practically significant: True ,  CI doesn't include d_min or -d_min\n"
     ]
    }
   ],
   "source": [
    "# gross conversion\n",
    "n = len(enrolls_exp)\n",
    "d_min = 0.01\n",
    "sum_clicks_cont = sum(clicks_cont[:n])\n",
    "sum_clicks_exp = sum(clicks_exp[:n])\n",
    "sum_enroll_cont = sum(enrolls_cont[:n])\n",
    "sum_enroll_exp = sum(enrolls_exp[:n])\n",
    "\n",
    "p_pool = (sum_enroll_exp + sum_enroll_cont)/(sum_clicks_exp + sum_clicks_cont)\n",
    "SE_pool = math.sqrt(p_pool * (1 - p_pool) * (1/sum_clicks_exp + 1/sum_clicks_cont))\n",
    "m = SE_pool * 1.96\n",
    "d_hat = sum_enroll_exp/sum_clicks_exp - sum_enroll_cont/sum_clicks_cont\n",
    "\n",
    "print(\"Confidence Interval:[{},{}]\".format(d_hat-m, d_hat+m))\n",
    "print(\"Observed:\", d_hat)\n",
    "print (\"Statistically significant:\", d_hat + m < 0 or d_hat - m > 0 ,\",  CI doesn't include 0\")\n",
    "print(\"Practically significant:\", True,\",  CI doesn't include d_min or -d_min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval:[0.008104435728019967,0.05408517368626556]\n",
      "Observed: 0.031094804707142765\n",
      "Statistically significant: True ,  CI doesn't include 0\n",
      "Practically significant: False ,  CI include d_min\n"
     ]
    }
   ],
   "source": [
    "# retention\n",
    "n = len(payment_exp)\n",
    "d_min = 0.01\n",
    "sum_payment_cont = sum(payment_cont[:n])\n",
    "sum_payment_exp = sum(payment_exp[:n])\n",
    "sum_enroll_cont = sum(enrolls_cont[:n])\n",
    "sum_enroll_exp = sum(enrolls_exp[:n])\n",
    "p_pool = (sum_payment_cont+sum_payment_exp) / (sum_enroll_cont+sum_enroll_exp)\n",
    "SE_pool = math.sqrt(p_pool*(1-p_pool)*(1/sum_enroll_cont+1/sum_enroll_exp))\n",
    "m=SE_pool*1.96\n",
    "d_hat=sum_payment_exp/sum_enroll_exp-sum_payment_cont/sum_enroll_cont\n",
    "print(\"Confidence Interval:[{},{}]\".format(d_hat-m,d_hat+m))\n",
    "print(\"Observed:\",d_hat)\n",
    "print (\"Statistically significant:\", d_hat+m<0 or d_hat-m>0 ,\",  CI doesn't include 0\")\n",
    "print(\"Practically significant:\",False,\",  CI include d_min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval:[-0.011604624359891718,0.001857179010803383]\n",
      "Observed: -0.0048737226745441675\n",
      "Statistically significant: False ,  CI doesn't include 0\n",
      "Practically significant: False ,  CI include d_min\n"
     ]
    }
   ],
   "source": [
    "# Net Conversion\n",
    "n=len(enrolls_exp)\n",
    "d_min=0.0075\n",
    "sum_clicks_cont=sum(clicks_cont[:n])\n",
    "sum_clicks_exp=sum(clicks_exp[:n])\n",
    "sum_payment_cont=sum(payment_cont[:n])\n",
    "sum_payment_exp=sum(payment_exp[:n])\n",
    "p_pool=(sum_payment_exp+sum_payment_cont)/(sum_clicks_exp+sum_clicks_cont)\n",
    "SE_pool=math.sqrt(p_pool*(1-p_pool)*(1/sum_clicks_cont+1/sum_clicks_exp))\n",
    "m=SE_pool*1.96\n",
    "d_hat=sum_payment_exp/sum_clicks_exp-sum_payment_cont/sum_clicks_cont\n",
    "print(\"Confidence Interval:[{},{}]\".format(d_hat-m,d_hat+m))\n",
    "print(\"Observed:\",d_hat)\n",
    "print (\"Statistically significant:\", d_hat+m<0 or d_hat-m>0 ,\",  CI doesn't include 0\")\n",
    "print(\"Practically significant:\",False,\",  CI include d_min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sign Tests\n",
    "For each of your evaluation metrics, do a sign test using the day-by-day data, and report the p-value of the sign test and whether the result is statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.0025994777679443364 , Statistically Significant: True\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom_test \n",
    "# gross conversion\n",
    "gc_exp=[i/j for i,j in zip(enrolls_exp,clicks_exp)]\n",
    "gc_cont=[i/j for i,j in zip(enrolls_cont,clicks_cont)]\n",
    "gc_diff=sum([i>j for i,j in zip(gc_exp,gc_cont)])\n",
    "days=len(gc_exp)\n",
    "\n",
    "# The prob of gross conversion of experiment group > gross conversion of control group is 0.5\n",
    "p_value=binom_test(gc_diff, n=days, p=0.5)\n",
    "print(\"p-value:\",p_value,\", Statistically Significant:\",p_value<0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.6776394844055175 , Statistically Significant: False\n"
     ]
    }
   ],
   "source": [
    "# retention\n",
    "rt_exp=[i/j for i,j in zip(payment_exp,enrolls_exp)]\n",
    "rt_cont=[i/j for i,j in zip(payment_cont,enrolls_cont)]\n",
    "rt_diff=sum([i>j for i,j in zip(rt_exp,rt_cont)])\n",
    "days=len(rt_exp)\n",
    "p_value=binom_test(rt_diff, n=days, p=0.5)\n",
    "print(\"p-value:\",p_value,\", Statistically Significant:\",p_value<0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.6776394844055175 , Statistically Significant: False\n"
     ]
    }
   ],
   "source": [
    "# net conversion\n",
    "nc_exp=[i/j for i,j in zip(payment_exp,clicks_exp)]\n",
    "nc_cont=[i/j for i,j in zip(payment_cont,clicks_cont)]\n",
    "nc_diff=sum([i>j for i,j in zip(nc_exp,nc_cont)])\n",
    "days=len(nc_exp)\n",
    "p_value=binom_test(nc_diff, n=days, p=0.5)\n",
    "print(\"p-value:\",p_value,\", Statistically Significant:\",p_value<0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "State whether you used the Bonferroni correction, and explain why or why not. If there are any discrepancies between the effect size hypothesis tests and the sign tests, describe the discrepancy and why you think it arose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I didn't use Bonferroni correction since it is too conservative and based on size tests, we could see most metrics nonsignificant. The reason why I think there is some discrepancies in Retention is because customers might pay their courses not day-by-day. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation\n",
    "Finally, make a recommendation. Would you launch this experiment, not launch it, dig deeper, run a follow-up experiment, or is it a judgment call? If you would dig deeper, explain what area you would investigate. If you would run follow-up experiments, briefIy describe that experiment. If it is a judgment call, explain what factors would be relevant to the decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wouldn't launch this experiment. It is clear that when it comes to payment, we could derive a conclusion that they will more likely pay for enrolled classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow-Up Experiment\n",
    "Give a high-level description of the follow up experiment you would run, what your hypothesis would be, what metrics you would want to measure, what your unit of diversion would be, and your reasoning for these choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would have follow-up experiment on why students don't pay for classes. It is because we don't provide good quality courses?\n",
    "\n",
    "I would set up an experiment that we provide longer free trials to see more retention and net conversion. \n",
    "\n",
    "The metric I will choose is retention and unit of diversion is user-id because we would like to know behaviors of customers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
